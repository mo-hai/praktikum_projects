{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта\n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### План работы\n",
    "\n",
    "[Bert](#b)\n",
    "1. [Подготовка данных](#b_1)\n",
    "2. [Обучение модели](#b_2)\n",
    "\n",
    "[tf-idf](#t)\n",
    "\n",
    "1. [Подготовка данных](#t_1)\n",
    "2. [Обучение модели](#t_2)\n",
    "\n",
    "[Выводы](#c)\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLP\n",
    "import torch\n",
    "import transformers\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "#from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(file_name, url):\n",
    "    if not os.path.exists(file_name):\n",
    "        print('Файл не найден и будет загружен из сети')\n",
    "        file_name, headers = urlretrieve(url)\n",
    "    return pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл не найден и будет загружен из сети\n",
      "Размер датасета: (159571, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'toxic_comments.csv'\n",
    "url = 'datasets/toxic_comments.csv'\n",
    "\n",
    "df = get_file(file_name, url)\n",
    "print('Размер датасета:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='b'></a>\n",
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='b_1'></a>\n",
    "### 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу выделим тестовую выборку и сбалансируем трейн с помощью downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер трейна (20000, 2)\n",
      "Размер теста (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=333)\n",
    "\n",
    "train_0 = train[train['toxic'] == 0].sample(10000, random_state=333)\n",
    "train_1 = train[train['toxic'] == 1].sample(10000, random_state=333)\n",
    "train = shuffle(pd.concat([train_0]+[train_1]))\n",
    "\n",
    "test = test.sample(10000, random_state=333)\n",
    "\n",
    "print('Размер трейна', train.shape)\n",
    "print('Размер теста', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Выполняем токенизацию каждого текста, то есть разбиваем на слова \n",
    "(Алгоритм лемматизации и очистки текста уже заложен в модели Bert)\n",
    "4. На выходе у каждого исходного текста образуется свой список токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 486)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# tockenize\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased')\n",
    "tokenized = train['text'].apply(\n",
    "    lambda x: tokenizer.encode(x[:512], add_special_tokens=True))\n",
    "\n",
    "# count max qty of tockens\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "# add 0 to strokes which lenght less than max\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "# make a mask to highlight important tockens\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Затем токены передаем модели, которая переводит их в векторные представления. Для этого модель обращается к составленному заранее словарю токенов. На выходе для каждого текста образуются векторы заданной длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [04:02<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "bert_model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model.to(device)\n",
    "\n",
    "batch_size = 50\n",
    "embeddings = []\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.cuda.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.cuda.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = bert_model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "\n",
    "train_x = np.concatenate(embeddings)\n",
    "train_y = train['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.5 GB\n",
      "Cached:    2.1 GB\n"
     ]
    }
   ],
   "source": [
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделываем все тоже самое с тестовой выборкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.96 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 127)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# tockenize\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased')\n",
    "tokenized = test['text'].apply(\n",
    "    lambda x: tokenizer.encode(x[:128], add_special_tokens=True))\n",
    "\n",
    "# count max qty of tockens\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "# add 0 to strokes which lenght less than max\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "# make a mask to highlight important tockens\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:27<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = torch.device('cuda')\n",
    "\n",
    "bert_model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model.to(device)\n",
    "\n",
    "batch_size = 50\n",
    "embeddings = []\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.cuda.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.cuda.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = bert_model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "\n",
    "test_x = np.concatenate(embeddings)\n",
    "test_y = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='b_2'></a>\n",
    "### 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. На финальном этапе модели передаем признаки (векторы). И она прогнозирует эмоциональную окраску текста — 0 («отрицательная») или 1 («положительная»)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на трейне: 0.7639659825838977\n",
      "f1 на тесте: 0.3242313480971834\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=333, class_weight='balanced', solver='liblinear')\n",
    "lr_model.fit(train_x, train_y)\n",
    "\n",
    "train_pred = lr_model.predict(train_x)\n",
    "test_pred = lr_model.predict(test_x)\n",
    "\n",
    "print('f1 на трейне:', f1_score(train_y, train_pred))\n",
    "print('f1 на тесте:', f1_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на трейне: 0.7255681392034801\n",
      "f1 на тесте: 0.2127566622979467\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier(random_state=333, class_weight='balanced')\n",
    "sgd_model.fit(train_x, train_y)\n",
    "\n",
    "train_pred = sgd_model.predict(train_x)\n",
    "test_pred = sgd_model.predict(test_x)\n",
    "\n",
    "print('f1 на трейне:', f1_score(train_y, train_pred))\n",
    "print('f1 на тесте:', f1_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тесте очень слабый показатель, возможно ситуация будет лучше если увеличить выборку и убрать downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t'></a>\n",
    "# tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t_1'></a>\n",
    "### 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(80000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Слова лемматризируем\n",
    "2. Текст очищаем от стоп-слов и ненужных символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmatize(text):\n",
    "    stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "    \n",
    "    words = text.split()\n",
    "    stemm_list = []\n",
    "    for word in words:\n",
    "        stemm_list.append(stemmer.stem(word))\n",
    "        \n",
    "    return ' '.join(stemm_list)\n",
    "\n",
    "\n",
    "def clear_text(text):\n",
    "    processed_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    processed_text = ' '.join(processed_text.split())\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['stem'] = df['text'].apply(lambda x: stemmatize(clear_text(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер трейна (64000, 2)\n",
      "Размер теста (16000, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=333)\n",
    "\n",
    "train_x = train.drop('toxic', axis=1)\n",
    "train_y = train['toxic']\n",
    "\n",
    "test_x = test.drop('toxic', axis=1)\n",
    "test_y = test['toxic']\n",
    "\n",
    "print('Размер трейна', train_x.shape)\n",
    "print('Размер теста', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Готовим векторы признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер трейна (64000, 75938)\n",
      "Размер теста (16000, 75938)\n",
      "Wall time: 4.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count_tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tf_idf = count_tfidf.fit_transform(np.array(train_x['stem']))\n",
    "train_x = pd.DataFrame(tf_idf.toarray())\n",
    "\n",
    "tf_idf = count_tfidf.transform(np.array(test_x['stem']))\n",
    "test_x = pd.DataFrame(tf_idf.toarray())\n",
    "\n",
    "print('Размер трейна', train_x.shape)\n",
    "print('Размер теста', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t_2'></a>\n",
    "### 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на трейне: 0.8447667842171802\n",
      "f1 на тесте: 0.7448503158472948\n",
      "Wall time: 9min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_model = LogisticRegression(random_state=333, class_weight='balanced', solver='liblinear')\n",
    "lr_model.fit(train_x, train_y)\n",
    "\n",
    "train_pred = lr_model.predict(train_x)\n",
    "test_pred = lr_model.predict(test_x)\n",
    "\n",
    "print('f1 на трейне:', f1_score(train_y, train_pred))\n",
    "print('f1 на тесте:', f1_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_model = SGDClassifier(random_state=333, class_weight='balanced')\n",
    "sgd_model.fit(train_x, train_y)\n",
    "\n",
    "train_pred = sgd_model.predict(train_x)\n",
    "test_pred = sgd_model.predict(test_x)\n",
    "\n",
    "print('f1 на трейне:', f1_score(train_y, train_pred))\n",
    "print('f1 на тесте:', f1_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='c'></a>\n",
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Балансировку классов провели с помощью внутринних механизмов моделей.\n",
    "\n",
    "Лучший результат f1 0.755 на тесте показала логистическая регрессия поверх tf-idf. Возможно лог регрессия поверх Bertа показала бы результат лучше при большей выборке."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
