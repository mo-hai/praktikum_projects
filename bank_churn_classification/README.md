# Предсказание оттока клиентов из банка

## Задача

Спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Исследование 3х моеделей машинного обучения: LogisticRegression, DecisionTree, RandomForest. Исследование разных методов борьбы с дисбалансом классов: upsampling, downsampling, внутринние механизмы моделей.

F1-мера должна быть не менее 0.6.

Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling

## Данные

В распоряжении исторические данные о поведении клиентов и расторжении договоров с банком:
- `RowNumber` — индекс строки в данных
- `CustomerId` — уникальный идентификатор клиента
- `Surname` — фамилия
- `CreditScore` — кредитный рейтинг
- `Geography` — страна проживания
- `Gender` — пол
- `Age` — возраст
- `Tenure` — количество недвижимости у клиента
- `Balance` — баланс на счёте
- `NumOfProducts` — количество продуктов банка, используемых клиентом
- `HasCrCard` — наличие кредитной карты
- `IsActiveMember` — активность клиента
- `EstimatedSalary` — предполагаемая зарплата

## Используемые библиотеки
*pandas*, *numpy*, *matplotlib*, *seaborn*, *sklearn* 

## Выводы:
- Подготовили данные для обучения: 
   - Удалили лишние признаки
   - Преобразовали категориальные признаки в численные методом OHE;
   - Отмасштабировали количественные признаки;
   - Провели анализ на мультиколлинеарность факторов, сильной корреляции между признаками не обнаружено;

- Исследовали поведение моделей без учета дисбаланса. На результат логистической регрессии дисбаланс сказывается сильно, тогда как на деревянных моделях не так заметно. У леса на сбалансированных данных метрика упала, но при настройки гиперпараметров лучши результат выходит на сбалансированных данных.

| ML model           | F1-score без учета дисбаланса | F1-score на сбалансированных данных |
|:-------------------|:------------------------------|:------------------------------------|
| LogisticRegression | 0.364                         | 0.499                               |
| DecisionTree       | 0.515                         | 0.534                               |
| RandomForest       | 0.70                          | 0.612                               |

- Исследовали разные методы борьбы с дисбалансом. Лучший результат показывают встроенные механизмы моделей, downsampling сильно просадил метрику у деревянных моделей. 

| ML model           | classweight='balanced' | upsampling   | downsampling |
|:-------------------|:-----------------------|:-------------|:-------------|
| LogisticRegression | 0.499                  | 0.494        | 0.495        |
| DecisionTree       | 0.534                  | 0.521        | 0.483        |
| RandomForest       | 0.612                  | 0.611        | 0.586        |

- Сравнили модели логистической регрессии, дерева решений и случайного леса с настроиными гиперпараметрами и на сбалансированных данных. Поиск гиперпараметров провели по сетке GridSearchCV. 

- На тесте лучший результат метрики f1-score 0.613 показала меодель случайного леса, AUC-ROC 0.77
